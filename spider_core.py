import os
import sys
import time
import random
import asyncio
import threading
import re
import json
import requests
import shutil
import winreg
from concurrent.futures import ThreadPoolExecutor
from playwright.async_api import async_playwright

# ================= ç»ˆç«¯é¢œè‰²é…ç½® =================
class Colors:
    RESET = "\033[0m"
    RED = "\033[91m"
    GREEN = "\033[92m"
    YELLOW = "\033[93m"
    BLUE = "\033[94m"
    CYAN = "\033[96m"
    GREY = "\033[90m"

def cprint(msg, level="info"):
    """é»˜è®¤çš„ CLI æ—¥å¿—å›è°ƒ"""
    ts = time.strftime('%H:%M:%S')
    if level == "info": color = Colors.BLUE
    elif level == "success": color = Colors.GREEN
    elif level == "warning": color = Colors.YELLOW
    elif level == "danger": color = Colors.RED
    elif level == "secondary": color = Colors.GREY
    else: color = Colors.RESET
    print(f"{Colors.GREY}[{ts}]{Colors.RESET} {color}{msg}{Colors.RESET}")

# ================= æµè§ˆå™¨è·¯å¾„è‡ªåŠ¨å¯»æ‰¾å·¥å…· =================
def find_system_browser(browser_type="edge"):
    browser_type = browser_type.lower()
    reg_key = r"SOFTWARE\Microsoft\Windows\CurrentVersion\App Paths\msedge.exe" if browser_type == "edge" else r"SOFTWARE\Microsoft\Windows\CurrentVersion\App Paths\chrome.exe"
    try:
        with winreg.OpenKey(winreg.HKEY_LOCAL_MACHINE, reg_key) as key:
            exe_path, _ = winreg.QueryValueEx(key, "")
            if os.path.exists(exe_path): return exe_path
    except:
        pass
    which_path = shutil.which(browser_type)
    if which_path: return which_path
    
    edge_paths = [
        r"C:\Program Files (x86)\Microsoft\Edge\Application\msedge.exe",
        r"C:\Program Files\Microsoft\Edge\Application\msedge.exe",
        os.path.expanduser(r"~\AppData\Local\Microsoft\Edge\Application\msedge.exe"),
    ]
    chrome_paths = [
        r"C:\Program Files\Google\Chrome\Application\chrome.exe",
        r"C:\Program Files (x86)\Google\Chrome\Application\chrome.exe",
        os.path.expanduser(r"~\AppData\Local\Google\Chrome\Application\chrome.exe"),
    ]
    target_paths = edge_paths if browser_type == "edge" else chrome_paths
    for path in target_paths:
        if os.path.exists(path): return path
    return None

# ================= é…ç½®æ–‡ä»¶ç®¡ç† =================
class ConfigManager:
    def __init__(self):
        self.config_file = "spider_config.json"
        self.default_config = {
            "save_path": os.path.join(os.getcwd(), "Download"), 
            "concurrency": 3,
            "download_threads": 16,
            "max_scrolls": 1000,
            "stop_thresh": 300,      # æ—§å›¾é˜ˆå€¼é»˜è®¤ 300
            "max_video_size": 5,
            "dl_images": True,
            "dl_gifs": True,
            "browser_type": "Edge",
            "create_link_file": True,
            "custom_likes_id": "",
            "deep_scan": False,
            "headless": False,
            "theme": "system",        # UI ä¸»é¢˜: system, light, dark
            "timeout": 60,          # è¶…æ—¶æ—¶é—´(ç§’)
            "use_tmp_files": True   # æ˜¯å¦ä½¿ç”¨ä¸´æ—¶æ–‡ä»¶ä¸‹è½½
        }
        self.data = self.load()

    def load(self):
        if os.path.exists(self.config_file):
            try:
                with open(self.config_file, "r", encoding="utf-8") as f:
                    data = json.load(f)
                    if "auto_phoenix_restart" in data: del data["auto_phoenix_restart"]
                    # è¡¥å…¨å¯èƒ½ç¼ºå¤±çš„é…ç½®
                    if "stop_thresh" not in data: data["stop_thresh"] = 300
                    if "timeout" not in data: data["timeout"] = 60
                    if "use_tmp_files" not in data: data["use_tmp_files"] = True
                    if "create_link_file" not in data: data["create_link_file"] = True
                    return {**self.default_config, **data}
            except:
                return self.default_config
        return self.default_config

    def save(self):
        try:
            with open(self.config_file, "w", encoding="utf-8") as f:
                json.dump(self.data, f, indent=4, ensure_ascii=False)
        except Exception as e:
            print(f"Config Save Error: {e}")

    def get(self, key):
        return self.data.get(key)

    def set(self, key, value):
        self.data[key] = value
        self.save()

CFG = ConfigManager()

# ================= é«˜æ€§èƒ½å¼‚æ­¥å¹¶å‘ä¸‹è½½ç®¡ç†å™¨ (æ”¯æŒæ¯«ç§’çº§ä¸­æ–­ + å°¸ä½“æ¸…ç†) =================
class DownloadManager:
    def __init__(self, callbacks=None, max_threads=16):
        self.queue = asyncio.Queue()
        self.executor = ThreadPoolExecutor(max_workers=max_threads)
        self.active_task_ids = set()
        self.session_counters = {}
        self.pending_tasks_map = {}
        self.is_running = False
        self.session = requests.Session()
        self.session.headers.update({
            "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36"
        })
        self.active_workers = []
        self.cbs = callbacks if callbacks else {}

    def _emit_log(self, msg, level="info"):
        if 'on_log' in self.cbs and self.cbs['on_log']:
            self.cbs['on_log'](msg, level)
        else:
            cprint(msg, level)

    async def start_workers(self, count=10):
        self.is_running = True
        self.active_workers = [asyncio.create_task(self._worker_logic()) for _ in range(count)]
        self._emit_log(f"ğŸš€ ä¸‹è½½è°ƒåº¦ä¸­æ¢å·²å°±ä½ (ä¸‹è½½çº¿ç¨‹: {self.executor._max_workers})", "info")

    async def stop_workers(self):
        self.is_running = False
        for _ in range(len(self.active_workers)):
            await self.queue.put(None)
        if self.active_workers:
            await asyncio.gather(*self.active_workers, return_exceptions=True)
        self.active_workers = []

    def register_task(self, tid):
        self.active_task_ids.add(tid)
        if tid not in self.session_counters: self.session_counters[tid] = 0
        if tid not in self.pending_tasks_map: self.pending_tasks_map[tid] = 0

    def deregister_task(self, tid):
        self.active_task_ids.discard(tid)
        self.pending_tasks_map[tid] = 0

    def get_pending_count(self, tid):
        return self.pending_tasks_map.get(tid, 0)

    async def submit_job(self, url, path, tid, label, f_type, clean_url, tweet_url):
        if tid not in self.active_task_ids: return
        self.pending_tasks_map[tid] = self.pending_tasks_map.get(tid, 0) + 1
        await self.queue.put({
            'url': url, 'path': path, 'tid': tid,
            'label': label, 'type': f_type,
            'clean_url': clean_url, 
            'tweet_url': tweet_url,
            'retry': 0
        })

    async def _worker_logic(self):
        while True:
            try:
                if not self.is_running and self.queue.empty(): break
                
                try:
                    item = await asyncio.wait_for(self.queue.get(), timeout=1.0)
                except asyncio.TimeoutError:
                    if not self.is_running: break
                    continue

                if item is None:
                    self.queue.task_done()
                    break

                tid = item['tid']
                if not self.is_running or tid not in self.active_task_ids:
                    self.pending_tasks_map[tid] = max(0, self.pending_tasks_map.get(tid, 0) - 1)
                    self.queue.task_done()
                    continue

                if item['type'] == 'vid':
                    try:
                        loop = asyncio.get_event_loop()
                        timeout = int(CFG.get('timeout'))
                        res = await loop.run_in_executor(self.executor, lambda: self.session.head(item['url'], timeout=timeout))
                        content_size = int(res.headers.get('Content-Length', 0))
                        limit_mb = float(CFG.get('max_video_size'))
                        if limit_mb > 0:
                            limit_bytes = limit_mb * 1024 * 1024
                            if content_size > limit_bytes: 
                                self.pending_tasks_map[tid] = max(0, self.pending_tasks_map.get(tid, 0) - 1)
                                self.queue.task_done()
                                continue
                    except:
                        self.pending_tasks_map[tid] = max(0, self.pending_tasks_map.get(tid, 0) - 1)
                        self.queue.task_done()
                        continue

                path = item['path']
                if os.path.exists(path) and os.path.getsize(path) > 1024:
                    self.pending_tasks_map[tid] = max(0, self.pending_tasks_map.get(tid, 0) - 1)
                    self.queue.task_done()
                    continue

                try:
                    loop = asyncio.get_event_loop()
                    success = await loop.run_in_executor(self.executor, self._sync_download, item['url'], path, tid)
                    if success:
                        self._record_history(item['clean_url'], tid, item.get('tweet_url'))
                        self.session_counters[tid] = self.session_counters.get(tid, 0) + 1
                        if 'on_progress' in self.cbs and self.cbs['on_progress']:
                            self.cbs['on_progress'](tid, self.session_counters[tid])
                    elif item['retry'] < 2 and self.is_running and tid in self.active_task_ids:
                        item['retry'] += 1
                        await self.queue.put(item)
                        continue
                except Exception:
                    pass
                finally:
                    self.pending_tasks_map[tid] = max(0, self.pending_tasks_map.get(tid, 0) - 1)
                    self.queue.task_done()
            except Exception:
                pass

    def _sync_download(self, url, path, tid):
        use_tmp = CFG.get("use_tmp_files")
        download_target = path + ".tmp" if use_tmp else path
        timeout = int(CFG.get('timeout'))
        
        try:
            os.makedirs(os.path.dirname(path), exist_ok=True)
            with self.session.get(url, timeout=timeout, stream=True) as r:
                if r.status_code == 200:
                    with open(download_target, "wb") as f:
                        for chunk in r.iter_content(chunk_size=16384):
                            if not self.is_running or tid not in self.active_task_ids:
                                f.close()
                                r.close()
                                if os.path.exists(download_target):
                                    try: os.remove(download_target)
                                    except: pass
                                return False
                            if chunk: f.write(chunk)
                    
                    if use_tmp and os.path.exists(download_target):
                        if os.path.exists(path):
                            try: os.remove(path)
                            except: pass
                        # å°è¯•ç§»åŠ¨æ–‡ä»¶ï¼ˆå¸¦é‡è¯•æœºåˆ¶ä»¥åº”å¯¹æ€æ¯’è½¯ä»¶é”å®šï¼‰
                        move_success = False
                        for _ in range(3):
                            try:
                                shutil.move(download_target, path)
                                move_success = True
                                break
                            except Exception:
                                import time
                                time.sleep(0.5)
                        
                        if not move_success:
                             # å¦‚æœæœ€ç»ˆç§»åŠ¨å¤±è´¥ï¼Œæ‰‹åŠ¨æŠ›å‡ºå¼‚å¸¸ä»¥è§¦å‘å¤–éƒ¨æ¸…ç†é€»è¾‘
                             raise Exception("File move failed after retries")
                    return True
            return False
        except:
            if os.path.exists(download_target):
                try: os.remove(download_target)
                except: pass
            return False

    def _record_history(self, url, tid, tweet_url=None):
        root = CFG.get('save_path')
        if not root: return
        p = os.path.join(root, "æˆ‘çš„å–œæ¬¢" if tid == "MY_LIKES" else "æˆ‘çš„ä¹¦ç­¾" if tid == "MY_BOOKMARKS" else f"åšä¸»å›¾é›†/{tid}")
        try:
            os.makedirs(p, exist_ok=True)
            raw_fname = url.split('/')[-1].split('?')[0]
            f_id = raw_fname.rsplit(".", 1)[0] if "." in raw_fname else raw_fname
            with open(os.path.join(p, "history.txt"), "a", encoding="utf-8") as f:
                f.write(f_id + "\n")
            if CFG.get("create_link_file") and tweet_url:
                with open(os.path.join(p, "link.txt"), "a", encoding="utf-8") as f:
                    f.write(f"{tweet_url}\t{f_id}\n")
        except: pass

# ================= æ ¸å¿ƒçˆ¬è™«å¼•æ“ =================
class CrawlerEngine:
    def __init__(self, callbacks=None):
        self.loop = None
        self.pw_instance = None
        self.browser_context = None
        self.queue = asyncio.Queue()
        self.running_tasks = {}
        self.semaphore = None
        self.is_running = False
        self.manual_shutdown = False
        self.engine_ready_event = asyncio.Event()
        self.is_ctx_alive = False
        self.cbs = callbacks if callbacks else {}
        self.dl_manager = DownloadManager(callbacks)
        # æš‚åœçŠ¶æ€ç®¡ç†
        self.paused_tasks = set()  # æš‚åœçš„ä»»åŠ¡ ID
        self.suspended_tasks = {}  # æŒ‚èµ·çš„ä»»åŠ¡ï¼ˆé‡Šæ”¾äº†æ§½ä½ï¼Œç­‰å¾…æ¢å¤ï¼‰
        self.global_paused = False
        self.completed_tasks = []  # æœ¬æ¬¡å¯åŠ¨å®Œæˆçš„ä»»åŠ¡
        self.failed_tasks = {}     # å¤±è´¥çš„ä»»åŠ¡ {tid: error_msg}
        self.transitioning_tasks = {} # æ­£åœ¨ç­‰å¾…ä¿¡å·é‡çš„ä»»åŠ¡ {tid: launcher_task}
        self.tid_to_page = {}      # ä»»åŠ¡ ID åˆ° Page å¯¹è±¡çš„æ˜ å°„ï¼Œé˜²æ­¢å¹½çµé¡µé¢

    def _emit_log(self, msg, level="info"):
        """æ¨é€æ—¥å¿—åˆ°å‰ç«¯"""
        if 'on_log' in self.cbs and self.cbs['on_log']:
            self.cbs['on_log'](msg, level)
        else:
            cprint(msg, level)

    def _broadcast_status(self):
        """ä¸»åŠ¨æ¨é€æœ€æ–°çŠ¶æ€åˆ°å‰ç«¯"""
        if 'on_task_update' in self.cbs and self.cbs['on_task_update']:
            try:
                self.cbs['on_task_update'](self.get_queue_status())
            except: pass

    def start(self):
        if self.is_running: return
        self.is_running = True
        self.manual_shutdown = False
        threading.Thread(target=self._run_loop, daemon=True).start()

    def add_task_to_queue(self, tid):
        if self.is_running and self.loop:
            # æŸ¥é‡ï¼šå¦‚æœåœ¨è¿è¡Œä¸­ã€æŒ‚èµ·ä¸­æˆ–å·²åœ¨é˜Ÿåˆ—ä¸­ï¼Œåˆ™æ‹’ç»
            if tid in self.running_tasks or tid in self.suspended_tasks or tid in self.paused_tasks:
                self._emit_log(f"âš ï¸ ä»»åŠ¡ [{tid}] å·²ç»åœ¨å¤„ç†ä¸­ï¼Œè¯·å‹¿é‡å¤æ·»åŠ ", "warning")
                return False
                
            # æ£€æŸ¥é˜Ÿåˆ—å†…éƒ¨
            queue_items = []
            try:
                queue_items = list(self.queue._queue)
            except: pass
            if tid in queue_items:
                self._emit_log(f"âš ï¸ ä»»åŠ¡ [{tid}] å·²åœ¨æ’é˜Ÿï¼Œè¯·å‹¿é‡å¤æ·»åŠ ", "warning")
                return False

            self.loop.call_soon_threadsafe(self.queue.put_nowait, tid)
            # æ·»åŠ åˆ°é˜Ÿåˆ—æ—¶ï¼Œæ¸…é™¤é”™è¯¯çŠ¶æ€
            self.failed_tasks.pop(tid, None)
            self._emit_log(f"â• ä»»åŠ¡ [{tid}] å·²æ·»åŠ è‡³é˜Ÿåˆ—", "info")
            return True
        else:
            self._emit_log("âš ï¸ å¼•æ“å°šæœªå°±ç»ª", "warning")
            return False

    def stop(self):
        self.manual_shutdown = True
        self.is_running = False
        if self.loop:
             asyncio.run_coroutine_threadsafe(self._shutdown_sequence(), self.loop)

    def _run_loop(self):
        self.loop = asyncio.new_event_loop()
        asyncio.set_event_loop(self.loop)
        self.loop.run_until_complete(self._engine_lifecycle())

    async def _engine_lifecycle(self):
        self._emit_log(f"ğŸš€ åˆå§‹åŒ–æ ¸å¿ƒ (é¡µé¢å¹¶å‘: {int(CFG.get('concurrency'))})", "info")
        
        dl_threads = int(CFG.get('download_threads'))
        self.dl_manager = DownloadManager(self.cbs, max_threads=dl_threads)
        await self.dl_manager.start_workers(count=12)
        
        self.semaphore = asyncio.Semaphore(int(CFG.get('concurrency')))

        await self._launch_context()
        if not self.browser_context: 
            self.is_running = False
            return

        self._emit_log("âœ… ç‰©ç†é“¾è·¯å¼€å¯ï¼Œç¯å¢ƒé¢„çƒ­ä¸­...", "success")
        if CFG.get("deep_scan"):
             self._emit_log("â›ï¸ æ³¨æ„ï¼šç©¿é€æ¨¡å¼ (Deep Scan) å·²å¼€å¯ï¼Œå°†å¼ºåˆ¶æ‰«æè‡³åº•éƒ¨", "warning")

        await asyncio.sleep(3)
        self.engine_ready_event.set()

        scheduler_task = asyncio.create_task(self._task_dispatcher())

        self.is_ctx_alive = True
        def on_close(_): 
            if self.is_running and not self.manual_shutdown:
                self._emit_log("âš ï¸ æµè§ˆå™¨å·²å…³é—­ï¼Œå¼•æ“åœæ­¢ã€‚", "warning")
            self.is_ctx_alive = False
            self.is_running = False

        self.browser_context.on("close", on_close)

        while self.is_running and self.is_ctx_alive:
            if not self.browser_context.pages: await self.browser_context.new_page()
            await asyncio.sleep(2)

        if scheduler_task: scheduler_task.cancel()
        self.engine_ready_event.clear()
        
        await self._shutdown_sequence()

    async def _launch_context(self):
        # ä¸¥æ ¼æ£€æŸ¥å¤ç”¨æ¡ä»¶ï¼šå˜é‡å­˜åœ¨ ä¸” ä»åœ¨è¿æ¥ä¸­
        if self.browser_context and self.pw_instance:
            try:
                # å°è¯•è®¿é—®å±æ€§ï¼Œå¦‚æœå·²ç»æ–­å¼€ä¼šæŠ›å¼‚å¸¸æˆ–è¿”å› False
                if self.browser_context.browser and self.browser_context.browser.is_connected():
                    self._emit_log("ğŸ”— æ­£åœ¨è¿é€šå·²æœ‰çš„æµè§ˆå™¨å®ä¾‹", "success")
                    return self.browser_context
            except:
                pass
            
            # å¦‚æœèµ°åˆ°è¿™é‡Œï¼Œè¯´æ˜æ³¨å…¥çš„å®ä¾‹å·²å¤±æ•ˆï¼Œéœ€è¦é‡ç½®
            self._emit_log("âš ï¸ æµè§ˆå™¨å®ä¾‹å·²ä¸¢å¤±ï¼Œæ­£åœ¨é‡æ–°åˆå§‹åŒ–...", "warning")
            self.browser_context = None

        user_data_path = os.path.abspath("my_browser_data")
        bt = CFG.get("browser_type")
        exe = find_system_browser(bt)
        if not exe:
            self._emit_log(f"âŒ å¯»å€å¤±è´¥: æœªæ‰¾åˆ° {bt} å†…æ ¸è·¯å¾„", "danger")
            return None
        
        is_headless = CFG.get("headless")
        timeout = int(CFG.get("timeout")) * 1000 # Playwright ä½¿ç”¨æ¯«ç§’

        if not self.pw_instance:
            self.pw_instance = await async_playwright().start()
            
        self.browser_context = await self.pw_instance.chromium.launch_persistent_context(
            user_data_dir=user_data_path, executable_path=exe,
            headless=is_headless,
            channel="msedge" if bt.lower() == "edge" else "chrome",
            args=["--disable-blink-features=AutomationControlled"], no_viewport=True,
            timeout=timeout
        )
        
        # ã€æ–°å¢ã€‘å¼ºåˆ¶æ¸…ç†éæ­£å¸¸å…³é—­ç•™ä¸‹çš„å†—ä½™æ ‡ç­¾é¡µ
        try:
            pages = self.browser_context.pages
            if len(pages) > 1:
                # ä¿ç•™ç¬¬ä¸€ä¸ªï¼Œå…³é—­å…¶ä½™æ‰€æœ‰
                for p in pages[1:]:
                    await p.close()
        except:
            pass

        return self.browser_context

    async def _shutdown_sequence(self):
        """å®Œå…¨å…³é—­å¼•æ“ï¼ˆè½¯ä»¶é€€å‡ºæ—¶è°ƒç”¨ï¼‰"""
        if not self.browser_context and (not self.dl_manager or not self.dl_manager.is_running): return

        self._emit_log("ğŸ›‘ æ­£åœ¨åœæ­¢å…¨é“¾è·¯é‡‡é›†...", "danger")
        if self.dl_manager: await self.dl_manager.stop_workers()
        
        for t in self.running_tasks.values(): t.cancel()
        self.running_tasks.clear()
        self.suspended_tasks.clear()
        self.paused_tasks.clear()

        # åªæœ‰å®Œå…¨é€€å‡ºæ—¶æ‰å…³é—­æµè§ˆå™¨
        if self.manual_shutdown:
            if self.browser_context:
                try: await self.browser_context.close()
                except: pass
            if hasattr(self, 'pw_instance') and self.pw_instance:
                try: await self.pw_instance.stop()
                except: pass
            self.browser_context = None
        
        self.is_running = False
        self._emit_log("ğŸ å¼•æ“å·²å®‰å…¨åœæœºã€‚", "success")

    def stop_crawling_only(self):
        """ä»…åœæ­¢çˆ¬å–é€»è¾‘ï¼Œä¸å…³é—­æµè§ˆå™¨ï¼ˆæ–°éœ€æ±‚ï¼‰"""
        self._emit_log("â¹ï¸ æ­£åœ¨åœæ­¢çˆ¬å–...", "warning")
        self.is_running = False
        
        # å¼ºåˆ¶å…³é—­ä¸‹è½½ç®¡ç†å™¨æ€»é—¸ï¼Œè§¦å‘å³æ—¶ä¸­æ–­æ£€æŸ¥
        if self.dl_manager:
            self.dl_manager.is_running = False
        
        # å–æ¶ˆæ‰€æœ‰è¿è¡Œä¸­çš„ä»»åŠ¡
        for tid, task in list(self.running_tasks.items()):
            task.cancel()
            if self.dl_manager:
                self.dl_manager.deregister_task(tid)
        self.running_tasks.clear()
        self.suspended_tasks.clear()
        
        # æ¸…ç©ºé˜Ÿåˆ—
        while not self.queue.empty():
            try:
                self.queue.get_nowait()
            except:
                break
        
        self._emit_log("â¹ï¸ çˆ¬å–å·²åœæ­¢ (åå°ä¸‹è½½å·²å¼ºåˆ¶ä¸­æ–­å¹¶æ¸…ç†)", "success")

    # ================= ä»»åŠ¡æ§åˆ¶æ–¹æ³• =================
    async def delete_task(self, tid):
        """åˆ é™¤ä»»åŠ¡ï¼ˆå¼ºåˆ¶å…³é—­å¯¹åº” Pageï¼‰"""
        deleted = False
        
        # å¦‚æœä»»åŠ¡æ­£åœ¨è¿è¡Œï¼Œå–æ¶ˆå¹¶å…³é—­ Page
        if tid in self.running_tasks:
            task = self.running_tasks[tid]
            task.cancel()
            deleted = True
            self._emit_log(f"ğŸ—‘ï¸ å·²åˆ é™¤è¿è¡Œä¸­ä»»åŠ¡: [{tid}]", "warning")
        
        # åŒæ ·éœ€è¦æ¸…ç†æ­£åœ¨è¿‡æ¸¡ä¸­ï¼ˆå·²å‡ºé˜Ÿä½†æœªè¿›å…¥ runningï¼‰çš„ä»»åŠ¡
        if hasattr(self, 'transitioning_tasks') and tid in self.transitioning_tasks:
            task = self.transitioning_tasks[tid]
            task.cancel()
            self.transitioning_tasks.pop(tid, None)
            deleted = True
            self._emit_log(f"ğŸ—‘ï¸ å·²åˆ é™¤è¿‡æ¸¡ä¸­ä»»åŠ¡: [{tid}]", "warning")
        
        # ä»é˜Ÿåˆ—ä¸­ç§»é™¤
        try:
            new_queue = asyncio.Queue()
            while not self.queue.empty():
                item = self.queue.get_nowait()
                if item != tid:
                    new_queue.put_nowait(item)
                else:
                    deleted = True
                    self._emit_log(f"ğŸ—‘ï¸ å·²ä»é˜Ÿåˆ—ç§»é™¤: [{tid}]", "warning")
            self.queue = new_queue
        except:
            pass
        
        # ä»ä¸‹è½½ç®¡ç†å™¨æ³¨é”€
        if self.dl_manager:
            self.dl_manager.deregister_task(tid)
        
        # ä»ä»»åŠ¡ä¸­ç§»é™¤
        self.running_tasks.pop(tid, None)
        self.failed_tasks.pop(tid, None)
        
        # ä»»åŠ¡çŠ¶æ€æ›´æ–°å›è°ƒ
        if 'on_task_update' in self.cbs and self.cbs['on_task_update']:
            self.cbs['on_task_update'](self.get_queue_status())

    def pause_task(self, tid):
        """æš‚åœå•ä¸ªä»»åŠ¡"""
        if hasattr(self, 'paused_tasks'):
            self.paused_tasks.add(tid)
        else:
            self.paused_tasks = {tid}
        self._emit_log(f"â¸ï¸ ä»»åŠ¡å·²æš‚åœ: [{tid}]", "info")

    def resume_task(self, tid):
        """æ¢å¤å•ä¸ªä»»åŠ¡"""
        # å¦‚æœåœ¨å¤±è´¥åˆ—è¡¨ä¸­ï¼Œåˆ™é‡æ–°åŠ å…¥é˜Ÿåˆ—
        if tid in self.failed_tasks:
            self.add_task_to_queue(tid)
            return

        if hasattr(self, 'paused_tasks') and tid in self.paused_tasks:
            self.paused_tasks.discard(tid)
            self._emit_log(f"â–¶ï¸ ä»»åŠ¡å·²æ¢å¤: [{tid}]", "info")

    def pause_all(self):
        """å…¨å±€æš‚åœ"""
        self.global_paused = True
        self._emit_log("â¸ï¸ å…¨å±€æš‚åœ", "warning")

    def resume_all(self):
        """å…¨å±€æ¢å¤"""
        self.global_paused = False
        if hasattr(self, 'paused_tasks'):
            self.paused_tasks.clear()
        self._emit_log("â–¶ï¸ å…¨å±€æ¢å¤", "success")

    async def clear_all_tasks(self):
        """æ¸…ç©ºæ‰€æœ‰ä»»åŠ¡"""
        self._emit_log("ğŸ—‘ï¸ æ­£åœ¨æ¸…ç©ºä»»åŠ¡åˆ—è¡¨...", "warning")
        
        # 1. å–æ¶ˆæ‰€æœ‰è¿è¡Œä¸­çš„ä»»åŠ¡
        for tid, task in list(self.running_tasks.items()):
            task.cancel()
        self.running_tasks.clear()
        
        # 2. å–æ¶ˆæ‰€æœ‰è¿‡æ¸¡ä¸­çš„ä»»åŠ¡ï¼ˆå¯åŠ¨å™¨ï¼‰
        for tid, task in list(self.transitioning_tasks.items()):
            task.cancel()
        self.transitioning_tasks.clear()
        
        # 3. æ¸…ç©ºå„ç§çŠ¶æ€é›†åˆ
        self.paused_tasks.clear()
        self.failed_tasks.clear()
        self.suspended_tasks.clear()
        
        # 4. æ¸…ç©ºé˜Ÿåˆ—
        while not self.queue.empty():
            try: self.queue.get_nowait()
            except: break
            
        # 5. æ¸…ç†ä¸‹è½½é¡¹ä¸æ³¨é”€ ID
        if self.dl_manager:
            for tid in list(self.dl_manager.active_task_ids):
                self.dl_manager.deregister_task(tid)
            self.dl_manager.session_counters.clear()
        
        # 6. é‡ç½®ä¿¡å·é‡ (é˜²æ­¢æ­»é”)
        if self.semaphore:
            self.semaphore = asyncio.Semaphore(int(CFG.get('concurrency')))
            
        # 7. æ¨é€çŠ¶æ€
        self._emit_log("ğŸ—“ï¸ ä»»åŠ¡åˆ—è¡¨å·²å®Œå…¨é‡ç½® (åå°ä¸‹è½½å·²å¼ºåˆ¶ä¸­æ–­)", "success")
        self._broadcast_status()

    def get_queue_status(self):
        """è·å–ä»»åŠ¡é˜Ÿåˆ—çŠ¶æ€"""
        status_list = []
        
        # è¿è¡Œä¸­çš„ä»»åŠ¡
        for tid in self.running_tasks.keys():
            is_paused = hasattr(self, 'paused_tasks') and tid in self.paused_tasks
            status_list.append({
                "id": tid,
                "status": "paused" if is_paused else "running",
                "progress": self.dl_manager.session_counters.get(tid, 0) if self.dl_manager else 0
            })
        
        # é˜Ÿåˆ—ä¸­ç­‰å¾…çš„ä»»åŠ¡ï¼ˆé€šè¿‡éå†é˜Ÿåˆ—å‰¯æœ¬ï¼‰
        try:
            queue_items = list(self.queue._queue)
            for tid in queue_items:
                if tid not in self.running_tasks:
                    status_list.append({
                        "id": tid,
                        "status": "queued",
                        "progress": 0
                    })
        except:
            pass
        
        # æ­£åœ¨ç­‰å¾…æ§½ä½çš„ä»»åŠ¡ï¼ˆå³è°ƒåº¦å™¨å·²å–èµ°ä½†å°šæœªå¼€å§‹æ‰§è¡Œï¼‰
        for tid in list(self.transitioning_tasks.keys()):
            if tid in self.running_tasks: continue # å¦‚æœå·²è¿›å…¥è¿è¡Œå­—å…¸ï¼Œåˆ™ç”±ä¸‹æ–¹å¾ªç¯æ¸²æŸ“
            is_paused = tid in self.paused_tasks or self.global_paused
            status_list.append({
                "id": tid,
                "status": "paused" if is_paused else "queued",
                "progress": 0
            })

        # å¤±è´¥çš„ä»»åŠ¡
        for tid, err in self.failed_tasks.items():
            status_list.append({
                "id": tid,
                "status": "error",
                "progress": self.dl_manager.session_counters.get(tid, 0) if self.dl_manager else 0,
                "error": err
            })
        
        return status_list

    def get_completed_tasks(self):
        """è·å–æœ¬æ¬¡å¯åŠ¨å®Œæˆçš„ä»»åŠ¡åˆ—è¡¨"""
        return self.completed_tasks[:50]  # æœ€å¤šè¿”å› 50 æ¡

    async def _task_dispatcher(self):
        while self.is_running:
            try:
                tid = await asyncio.wait_for(self.queue.get(), timeout=1.0)
                # äº§ç”Ÿä¸€ä¸ªéé˜»å¡å¯åŠ¨å™¨ï¼Œé˜²æ­¢ acquire å¯¼è‡´ dispatcher æš‚åœå·¥ä½œ
                launcher = asyncio.create_task(self._task_launcher(tid))
                self.transitioning_tasks[tid] = launcher
            except:
                pass

    async def _task_launcher(self, tid):
        """è´Ÿè´£ç­‰å¾…ä¿¡å·é‡å¹¶å¯åŠ¨æ‰§è¡Œå™¨çš„ä¸­é—´å±‚"""
        try:
            while self.is_running:
                # 1. å¦‚æœåœ¨ç­‰å¾…æœŸé—´è¢«æš‚åœï¼Œåˆ™ä¸€ç›´ç­‰ç›´åˆ°æ¢å¤æˆ–å¼•æ“åœæ­¢
                while (tid in self.paused_tasks or self.global_paused) and self.is_running:
                    await asyncio.sleep(1)
                
                if not self.is_running: return

                # 2. è·å–ä¿¡å·é‡ï¼ˆæ­¤æ—¶å¦‚æœæ’åœ¨å‰é¢çš„ä»»åŠ¡æ²¡æš‚åœï¼Œå®ƒä¼šåœ¨è¿™é‡Œé˜»å¡ï¼‰
                self._emit_log(f"â³ ä»»åŠ¡ [{tid}] æ­£åœ¨ç­‰å¾…å¯ç”¨æ§½ä½...", "secondary")
                await self.semaphore.acquire()
                
                # 3. æ‹¿åˆ°ä¿¡å·é‡åï¼Œå†æ¬¡æ£€æŸ¥æ˜¯å¦åœ¨ç­‰å¾…æœŸé—´åˆå˜ä¸ºäº†æš‚åœçŠ¶æ€
                if (tid in self.paused_tasks or self.global_paused) and self.is_running:
                    self.semaphore.release()
                    continue
                
                # 4. æ­£å¼è¿›å…¥æ‰§è¡Œ
                await self._wrapped_executor(tid)
                break
        except asyncio.CancelledError:
            pass
        finally:
            self.transitioning_tasks.pop(tid, None)

    async def _wrapped_executor(self, tid):
        """ä»»åŠ¡æ‰§è¡Œå™¨ï¼šæ”¯æŒæš‚åœé‡Šæ”¾æ§½ä½"""
        try:
            self.dl_manager.register_task(tid)
            self._emit_log(f"â–¶ å¯åŠ¨ä»»åŠ¡: [{tid}]", "info")
            
            root = CFG.get('save_path')
            p = os.path.join(root, "æˆ‘çš„å–œæ¬¢" if tid == "MY_LIKES" else "æˆ‘çš„ä¹¦ç­¾" if tid == "MY_BOOKMARKS" else f"åšä¸»å›¾é›†/{tid}")
            self._archaeology_healing(p, tid)

            mission = asyncio.create_task(self._mission_body_logic(tid))
            self.running_tasks[tid] = mission
            
            try:
                status = await mission
            except asyncio.CancelledError:
                # ä»»åŠ¡è¢«å–æ¶ˆï¼ˆåˆ é™¤æ—¶ï¼‰
                self._emit_log(f"ğŸ—‘ï¸ ä»»åŠ¡ [{tid}] å·²è¢«åˆ é™¤", "warning")
                status = "CANCELLED"

            if status == "FINISHED":
                while self.dl_manager.get_pending_count(tid) > 0 and self.is_running:
                    await asyncio.sleep(2)
                self._emit_log(f"âœ… ä»»åŠ¡ [{tid}] å®Œæˆ", "success")
                # è®°å½•å®Œæˆçš„ä»»åŠ¡
                self.completed_tasks.insert(0, {
                    "id": tid,
                    "time": __import__('datetime').datetime.now().strftime("%H:%M:%S")
                })
                # ä»»åŠ¡å®Œæˆï¼Œä¸”æˆåŠŸç§»é™¤
                if 'on_task_finished' in self.cbs and self.cbs['on_task_finished']:
                    self.cbs['on_task_finished'](tid)

            elif status == "PAUSED":
                # ä»»åŠ¡è¢«æš‚åœï¼Œé‡Šæ”¾æ§½ä½ç­‰å¾…æ¢å¤
                self._emit_log(f"â¸ï¸ ä»»åŠ¡ [{tid}] å·²æŒ‚èµ·ï¼Œç­‰å¾…æ¢å¤", "info")
            elif status == "FAILED":
                # ä»»åŠ¡æ˜¾å¼è¿”å›å¤±è´¥çŠ¶æ€
                self.failed_tasks[tid] = "ä»»åŠ¡æ‰§è¡Œå¤±è´¥"
                self._emit_log(f"âŒ ä»»åŠ¡ [{tid}] æ‰§è¡Œå¤±è´¥", "danger")
            elif status != "CANCELLED":
                self._emit_log(f"âš ï¸ ä»»åŠ¡ [{tid}] ç»“æŸçŠ¶æ€: {status}", "warning")
        except Exception as e:
            self.failed_tasks[tid] = str(e)
            self._emit_log(f"âŒ ä»»åŠ¡ [{tid}] æ‰§è¡Œå¼‚å¸¸: {e}", "danger")
        finally:
            self.semaphore.release()
            self.running_tasks.pop(tid, None)
            try:
                self.queue.task_done()
            except:
                pass

    async def _sniff_and_save_id(self, page):
        """ä¸»åŠ¨å—…æ¢ç”¨æˆ· ID å¹¶ä¿å­˜"""
        self._emit_log(f"ğŸ” æ­£åœ¨æ ¸å®å½“å‰è´¦å·èº«ä»½...", "info")
        try:
            # 1. å›åˆ°ä¸»é¡µ
            await page.goto("https://x.com/home", timeout=30000)
            
            # 2. å®šä½ Profile æŒ‰é’®
            profile_btn = page.locator('a[data-testid="AppTabBar_Profile_Link"]')
            await profile_btn.wait_for(state="attached", timeout=10000)
            
            # 3. è¯»å– href
            href_attr = await profile_btn.get_attribute("href")
            
            if href_attr:
                real_user_id = href_attr.strip("/")
                CFG.set("custom_likes_id", real_user_id)
                self._emit_log(f"âœ… èº«ä»½ç¡®è®¤: @{real_user_id}", "success")
                return real_user_id
            return None
        except Exception as e:
            self._emit_log(f"âŒ æ— æ³•è¯†åˆ«è´¦å·èº«ä»½: {e}", "danger")
            return None

    def _archaeology_healing(self, path, tid):
        h_file = os.path.join(path, "history.txt")
        if not os.path.exists(h_file) and os.path.exists(path):
            ids = []
            for sub in ["å›¾ç‰‡", "Gif"]:
                p = os.path.join(path, sub)
                if os.path.exists(p):
                    for f in os.listdir(p): ids.append(os.path.splitext(f)[0])
            if ids:
                with open(h_file, "w", encoding="utf-8") as f:
                    for rid in set(ids): f.write(rid + "\n")
                self._emit_log(f"ğŸ§  [{tid}] è€ƒå¤å®Œæˆï¼Œæ¢å¤è®°å½• {len(ids)} æ¡", "secondary")

    async def resilient_goto(self, page, url, tid):
        timeout = int(CFG.get('timeout')) * 1000
        for i in range(3):
            try:
                await self.engine_ready_event.wait()
                await page.goto(url, timeout=timeout, wait_until="domcontentloaded")
                return True
            except Exception as e:
                if "ERR_ABORTED" in str(e):
                    await asyncio.sleep(2)
                    continue
                raise e
        return False

    async def _mission_body_logic(self, tid):
        if not self.is_running or not self.browser_context: return "FAILED"
        save_root = CFG.get('save_path')
        target_url = f"https://x.com/{tid}/media"
        task_label = tid
        save_dir = os.path.join(save_root, "åšä¸»å›¾é›†", tid)

        if tid == "MY_BOOKMARKS":
            target_url = "https://x.com/i/bookmarks"
            task_label = "ä¹¦ç­¾"
            save_dir = os.path.join(save_root, "æˆ‘çš„ä¹¦ç­¾")
        elif tid == "MY_LIKES":
            my_id = CFG.get("custom_likes_id")
            if not my_id: 
                # å°è¯•ä¸»åŠ¨å—…æ¢
                # æ­¤æ—¶é¡µé¢å¯èƒ½è¿˜æ²¡æ‰“å¼€ï¼Œéœ€è¦å…ˆåˆ›å»ºé¡µé¢
                # ä½† logic å†…éƒ¨ä¼šåˆ›å»ºé¡µé¢ï¼Œæ‰€ä»¥æˆ‘ä»¬åœ¨ logic è·å–é¡µé¢ååšä¸€æ¬¡å—…æ¢
                pass 
            else:
                target_url = f"https://x.com/{my_id}/likes"
            
            task_label = "å–œæ¬¢"
            save_dir = os.path.join(save_root, "æˆ‘çš„å–œæ¬¢")

        state = {"active": False, "streak": 0}
        history = self._get_local_history(save_dir)

        def get_tweet_url(item_data):
            try:
                core_data = item_data.get("itemContent", item_data)
                if "tweet_results" in core_data and "result" in core_data["tweet_results"]:
                    res = core_data["tweet_results"]["result"]
                    legacy = res.get("legacy") or res.get("tweet", {}).get("legacy")
                    core = res.get("core") or res.get("tweet", {}).get("core")
                    
                    if legacy:
                        t_id = legacy.get("id_str")
                        u_name = "i"
                        try: u_name = core["user_results"]["result"]["legacy"]["screen_name"]
                        except: pass
                        if t_id: return f"https://x.com/{u_name}/status/{t_id}"
            except: pass
            return None

        def pinpoint_extract(data):
            found = []
            if isinstance(data, dict):
                if "itemContent" in data or "tweet_results" in data:
                    t_url = get_tweet_url(data)
                    
                    def find_media(d, link):
                        res = []
                        if isinstance(d, dict):
                            if "media_url_https" in d:
                                u = d["media_url_https"]
                                if "/media/" in u and "profile_images" not in u: 
                                    res.append({'type': 'img', 'url': u, 'link': link})
                            if "video_info" in d and "variants" in d["video_info"]:
                                mp4s = [v for v in d["video_info"]["variants"] if v.get("content_type") == "video/mp4"]
                                if mp4s: 
                                    best = max(mp4s, key=lambda x: x.get("bitrate", 0))["url"]
                                    res.append({'type': 'vid', 'url': best, 'link': link})
                            for v in d.values(): res.extend(find_media(v, link))
                        elif isinstance(d, list):
                            for i in d: res.extend(find_media(i, link))
                        return res
                    
                    found.extend(find_media(data, t_url))
                    return found
                
                for v in data.values(): found.extend(pinpoint_extract(v))
            elif isinstance(data, list):
                for i in data: found.extend(pinpoint_extract(i))
            return found

        async def api_handler(res):
            markers = ["UserMedia", "UserTweets", "Bookmarks", "Likes", "Timeline"]
            if not any(m in res.url for m in markers) or not state["active"]: return
            try:
                json_data = await res.json()
                media_list = pinpoint_extract(json_data)
                
                for item in media_list:
                    raw_url = item['url']
                    t_link = item['link']
                    clean = raw_url.split("?")[0]
                    
                    raw_fname = clean.split('/')[-1]
                    if "." in raw_fname:
                         f_id = raw_fname.rsplit(".", 1)[0]
                    else:
                         f_id = raw_fname
                    
                    if f_id in history:
                        state["streak"] += 1
                        continue
                    state["streak"] = 0
                    
                    if item['type'] == 'img' and CFG.get("dl_images"):
                        dest = os.path.join(save_dir, "å›¾ç‰‡", f_id + ".jpg")
                        await self.dl_manager.submit_job(f"{clean}?format=jpg&name=orig", dest, tid, task_label, 'img', clean, t_link)
                        history.add(f_id)
                    elif item['type'] == 'vid' and CFG.get("dl_gifs"):
                        dest = os.path.join(save_dir, "Gif", f_id + ".mp4")
                        await self.dl_manager.submit_job(clean, dest, tid, task_label, 'vid', clean, t_link)
                        history.add(f_id)
            except:
                pass

        try:
            # ã€å¹½çµé¡µé¢æŸ¥é‡ã€‘æ£€æŸ¥æ˜¯å¦å·²æœ‰è¯¥ä»»åŠ¡å¯¹åº”çš„é¡µé¢
            page = None
            if tid in self.tid_to_page:
                old_page = self.tid_to_page[tid]
                try:
                    if not old_page.is_closed():
                        page = old_page
                        self._emit_log(f"ğŸ§  [{task_label}] æ£€æµ‹åˆ°å·²æœ‰é¡µé¢ï¼Œæ­£åœ¨å¤ç”¨è¿›è¡ŒåŒæ­¥", "secondary")
                    else:
                        del self.tid_to_page[tid]
                except:
                    del self.tid_to_page[tid]

            if not page:
                page = await self.browser_context.new_page()
                self.tid_to_page[tid] = page

            page.on("response", lambda r: asyncio.create_task(api_handler(r)))
            state["active"] = True

            # ã€ID ç¼“å­˜æœºåˆ¶ã€‘
            if tid == "MY_LIKES" and not CFG.get("custom_likes_id"):
                sniffed_id = await self._sniff_and_save_id(page)
                if sniffed_id:
                     target_url = f"https://x.com/{sniffed_id}/likes"
                else:
                     return "FAILED"

            if not await self.resilient_goto(page, target_url, task_label): return "FAILED"

            try: await page.wait_for_selector('[data-testid="tweet"]', timeout=20000)
            except: pass
            
            self._emit_log(f"âœ… [{task_label}] é¡µé¢åŠ è½½å®Œæ¯•ï¼Œå¼€å§‹é‡‡é›†", "success")
            await asyncio.sleep(5)

            shake_retry = 0
            for i in range(int(CFG.get('max_scrolls'))):
                if not self.is_running or not self.is_ctx_alive: return "FAILED"
                
                # ã€æš‚åœæ£€æŸ¥ä¸ä¿¡å·é‡äº¤æ¥ã€‘
                if tid in self.paused_tasks or self.global_paused:
                    self._emit_log(f"â¸ï¸ ä»»åŠ¡ [{tid}] æ­£åœ¨æš‚åœå¹¶é‡Šæ”¾èµ„æº...", "info")
                    self.semaphore.release() # é‡Šæ”¾æ§½ä½ç»™åˆ«äºº
                    try:
                        while (tid in self.paused_tasks or self.global_paused) and self.is_running:
                            await asyncio.sleep(1)
                        
                        if not self.is_running: return "FAILED"
                        
                        self._emit_log(f"â³ ä»»åŠ¡ [{tid}] æ­£åœ¨å°è¯•æ¢å¤å¹¶é‡æ–°æ’é˜Ÿ...", "info")
                        await self.semaphore.acquire() # é‡æ–°æ’é˜Ÿ
                        self._emit_log(f"â–¶ï¸ ä»»åŠ¡ [{tid}] å·²æˆåŠŸæ¢å¤è¿è¡Œ", "success")
                    except Exception as e:
                        self._emit_log(f"âŒ ä»»åŠ¡ [{tid}] æ¢å¤å¤±è´¥: {e}", "danger")
                        return "FAILED"

                # ã€æ ¸å¿ƒä¿®æ”¹ã€‘è¯»å–é…ç½®ä¸­çš„é˜ˆå€¼
                stop_limit = int(CFG.get('stop_thresh'))
                if not CFG.get("deep_scan") and state["streak"] >= stop_limit: 
                    self._emit_log(f"ğŸ›‘ [{task_label}] è¿ç»­ {stop_limit} å¼ æ—§å›¾ï¼Œåœæ­¢", "success")
                    break
                elif CFG.get("deep_scan") and state["streak"] > 0 and state["streak"] % 100 == 0:
                    self._emit_log(f"â›ï¸ [{task_label}] ç©¿é€æ¨¡å¼è¿è¡Œä¸­... å·²å¿½ç•¥ {state['streak']} å¼ æ—§å›¾", "secondary")

                prev_h = await page.evaluate("document.body.scrollHeight")
                await page.keyboard.press("End")
                
                # æ»šåŠ¨åçš„ç­‰å¾…ä¹Ÿè¦åˆ†ç‰‡ï¼Œä»¥ä¾¿å¿«é€Ÿå“åº”æš‚åœ/åœæ­¢
                wait_time = random.uniform(5, 8)
                for _ in range(int(wait_time)):
                     if not self.is_running or tid in self.paused_tasks or self.global_paused: break
                     await asyncio.sleep(1)
                
                new_h = await page.evaluate("document.body.scrollHeight")

                if new_h == prev_h:
                    shake_retry += 1
                    
                    is_rate_limited = await page.get_by_text("Rate limit exceeded").count() > 0 or \
                                      await page.get_by_text("Cannot retrieve tweets").count() > 0
                    if is_rate_limited:
                         self._emit_log(f"â›” [{task_label}] è§¦å‘æ¨ç‰¹é™æµï¼Œåœæ­¢è´¦å·ä¿æŠ¤ï¼", "danger")
                         return "FAILED"

                    retry_btn = page.get_by_role("button", name=re.compile(r"Retry|Try again", re.I))
                    if await retry_btn.count() > 0:
                         self._emit_log(f"ğŸ”„ [{task_label}] æ£€æµ‹åˆ°é‡è¯•æŒ‰é’®ï¼Œå°è¯•ç‚¹å‡»...", "warning")
                         await retry_btn.click()
                         await asyncio.sleep(5)
                         shake_retry = 0
                         continue

                    if shake_retry < 3:
                        self._emit_log(f"â³ [{task_label}] é¡µé¢æœªæ»šåŠ¨ï¼Œé‡è¯• {shake_retry}...", "warning")
                        await page.evaluate("window.scrollBy(0, -600)")
                        await asyncio.sleep(3)
                        await page.keyboard.press("End")
                        await asyncio.sleep(shake_retry * 5)
                        continue
                    else:
                        self._emit_log(f"ğŸ›‘ [{task_label}] é¡µé¢åˆ°åº•", "success")
                        break
                else:
                    shake_retry = 0
            return "FINISHED"
        except Exception as e:
            self._emit_log(f"âŒ [{task_label}] ä»»åŠ¡å¼‚å¸¸: {e}", "danger")
            return "FAILED"
        finally:
            try: 
                if tid in self.tid_to_page:
                    self.tid_to_page.pop(tid)
                await page.close()
            except: pass

    def _get_local_history(self, path):
        s = set()
        h = os.path.join(path, "history.txt")
        if os.path.exists(h):
            try:
                with open(h, "r", encoding="utf-8") as f:
                    for line in f: s.add(line.strip())
            except: pass
        return s

    async def run_login(self):
        bt = CFG.get("browser_type")
        exe = find_system_browser(bt)
        if not exe: 
            self._emit_log("æœªæ‰¾åˆ°æµè§ˆå™¨å†…æ ¸", "danger")
            return
        self._emit_log("ğŸ”‘ æ­£åœ¨å¼€å¯ç‹¬ç«‹ç™»å½•ç¯å¢ƒæˆæƒå‘å¯¼...", "warning")
        async with async_playwright() as p:
            ctx = await p.chromium.launch_persistent_context(
                user_data_dir=os.path.abspath("my_browser_data"), executable_path=exe,
                headless=False, channel="msedge" if bt.lower() == "edge" else "chrome",
                args=["--disable-blink-features=AutomationControlled"], no_viewport=True
            )
            page = ctx.pages[0]
            await page.goto("https://x.com/i/flow/login", timeout=0)
            self._emit_log("è¯·åœ¨å¼¹å‡ºçš„æµè§ˆå™¨ä¸­ç™»å½• Twitterï¼Œå®Œæˆåå…³é—­æµè§ˆå™¨çª—å£ã€‚", "info")
            while True:
                if not ctx.pages: break
                await asyncio.sleep(1)
            self._emit_log("âœ… æˆæƒç¯å¢ƒå·²æ›´æ–°å¹¶è½ç›˜", "success")

    # ã€æ–°å¢ã€‘å¯¼å‡º Cookie é€»è¾‘
    def export_cookies(self):
        src = os.path.abspath("my_browser_data")
        if not os.path.exists(src):
            cprint("âŒ æœªæ‰¾åˆ°ç™»å½•æ•°æ®ï¼Œæ— æ³•å¯¼å‡º", "danger")
            return
        
        dest = os.path.join(os.getcwd(), "cookies_backup.json")
        async def extract():
            async with async_playwright() as p:
                bt = CFG.get("browser_type")
                exe = find_system_browser(bt)
                ctx = await p.chromium.launch_persistent_context(
                    user_data_dir=src, executable_path=exe, headless=True,
                    channel="msedge" if bt.lower() == "edge" else "chrome"
                )
                storage = await ctx.storage_state(path=dest)
                await ctx.close()
                cprint(f"âœ… Cookie å·²å¯¼å‡ºè‡³: {dest}", "success")
        
        asyncio.run(extract())

# ================= æ–°å¢ï¼šå†å²ç»Ÿè®¡åŠŸèƒ½ =================
def print_stats():
    root = CFG.get("save_path")
    if not root or not os.path.exists(root):
        cprint("âŒ å­˜å‚¨è·¯å¾„ä¸å­˜åœ¨ï¼Œæ— æ³•ç»Ÿè®¡", "danger")
        return

    def count_lines(folder_name, sub_folder=None):
        if sub_folder:
            path = os.path.join(root, folder_name, sub_folder, "history.txt")
        else:
            path = os.path.join(root, folder_name, "history.txt")
        
        if os.path.exists(path):
            try:
                with open(path, "r", encoding="utf-8") as f:
                    return sum(1 for line in f if line.strip())
            except: return 0
        return 0

    cprint("\nğŸ“Š æœ¬åœ°å†å²è®°å½•ç»Ÿè®¡:", "info")
    print("-" * 30)

    likes = count_lines("æˆ‘çš„å–œæ¬¢")
    marks = count_lines("æˆ‘çš„ä¹¦ç­¾")
    
    if os.path.exists(os.path.join(root, "æˆ‘çš„å–œæ¬¢")):
        print(f"â¤ï¸  æˆ‘çš„å–œæ¬¢    : {likes} å¼ ")
    if os.path.exists(os.path.join(root, "æˆ‘çš„ä¹¦ç­¾")):
        print(f"ğŸ”– æˆ‘çš„ä¹¦ç­¾    : {marks} å¼ ")

    users_root = os.path.join(root, "åšä¸»å›¾é›†")
    if os.path.exists(users_root):
        print("-" * 30)
        for user_dir in os.listdir(users_root):
            full_path = os.path.join(users_root, user_dir)
            if os.path.isdir(full_path):
                cnt = count_lines("åšä¸»å›¾é›†", user_dir)
                print(f"ğŸ‘¤ {user_dir:<12} : {cnt} å¼ ")
    
    print("-" * 30)


# ================= å‘½ä»¤è¡Œæ¥å£ =================
def main():
    os.system('cls' if os.name == 'nt' else 'clear')
    cprint("========================================", "info")
    cprint("   X-Spider CLI (Ultimate v9.0)", "info")
    cprint("========================================", "info")
    
    if not os.path.exists("my_browser_data"):
        cprint("âš ï¸ æœªæ£€æµ‹åˆ°ç™»å½•ä¿¡æ¯ï¼Œè¯·å…ˆæ‰§è¡Œ 'login' å‘½ä»¤", "warning")
    else:
        cprint("âœ… ç™»å½•å‡­è¯å°±ç»ª", "success")

    engine = CrawlerEngine()
    engine.start()

    cprint("\næŒ‡ä»¤åˆ—è¡¨:", "secondary")
    cprint("  add <id>    : æ·»åŠ åšä¸»", "secondary")
    cprint("  likes       : ä¸‹è½½å–œæ¬¢", "secondary")
    cprint("  marks       : ä¸‹è½½ä¹¦ç­¾", "secondary")
    cprint("  path <dir>  : ä¿®æ”¹è·¯å¾„", "secondary")
    cprint("  threads <n> : ä¸‹è½½çº¿ç¨‹", "secondary")
    cprint("  pages <n>   : é¡µé¢å¹¶å‘", "secondary")
    cprint("  limit <MB>  : è§†é¢‘é™åˆ¶", "secondary")
    cprint("  thresh <n>  : æ—§å›¾é˜ˆå€¼", "secondary")
    cprint("  timeout <n> : è¶…æ—¶è®¾ç½®", "secondary")
    cprint("  browser <t> : å†…æ ¸åˆ‡æ¢(edge/chrome)", "secondary")
    cprint("  img on/off  : å›¾ç‰‡å¼€å…³", "secondary")
    cprint("  vid on/off  : è§†é¢‘å¼€å…³", "secondary")
    cprint("  deep on/off : ç©¿é€å¼€å…³", "secondary")
    cprint("  head on/off : æ— å¤´å¼€å…³", "secondary")
    cprint("  stats       : å†å²ç»Ÿè®¡", "secondary")
    cprint("  export      : å¯¼å‡ºCookie", "secondary")
    cprint("  config      : æŸ¥çœ‹é…ç½®", "secondary")
    cprint("  login       : å¯åŠ¨ç™»å½•", "secondary")
    cprint("  exit        : é€€å‡º", "secondary")
    print("")

    try:
        while True:
            cmd_raw = input(f"{Colors.CYAN}X-Spider>{Colors.RESET} ").strip()
            if not cmd_raw: continue
            
            if 'path ' in cmd_raw:
                parts = ['path', cmd_raw[5:].strip('"')]
            else:
                parts = cmd_raw.split()
                
            cmd = parts[0].lower()
            
            if cmd == "exit" or cmd == "stop" or cmd == "quit":
                engine.stop()
                break
            
            elif cmd == "add":
                if len(parts) > 1:
                    raw_args = parts[1]
                    ids = re.findall(r'@?([a-zA-Z0-9_]+)', raw_args)
                    final_ids = set()
                    for i in ids:
                        if i.lower() not in ['x', 'com', 'https', 'http', 'twitter', 'www']: final_ids.add(i)
                    for tid in final_ids: engine.add_task_to_queue(tid)
                else: cprint("ç”¨æ³•: add <id/url>", "warning")
            
            elif cmd == "likes": engine.add_task_to_queue("MY_LIKES")
            elif cmd == "marks": engine.add_task_to_queue("MY_BOOKMARKS")

            elif cmd == "path":
                if len(parts) > 1:
                    new_path = parts[1]
                    if os.path.isdir(new_path) or not os.path.exists(new_path):
                        try:
                            if not os.path.exists(new_path): os.makedirs(new_path)
                            CFG.set("save_path", new_path)
                            cprint(f"ğŸ“‚ è·¯å¾„å·²æ›´æ–°: {new_path}", "success")
                        except: cprint("âŒ è·¯å¾„æ— æ•ˆ", "danger")
                    else: cprint("âŒ è·¯å¾„æ— æ•ˆ", "danger")
                else: cprint(f"å½“å‰è·¯å¾„: {CFG.get('save_path')}", "info")

            elif cmd == "limit":
                if len(parts) > 1 and parts[1].isdigit():
                    v = int(parts[1])
                    CFG.set("max_video_size", v)
                    cprint(f"ğŸï¸ è§†é¢‘é™åˆ¶: {v}MB", "success")

            elif cmd == "threads":
                if len(parts) > 1 and parts[1].isdigit():
                    n = int(parts[1])
                    if 1 <= n <= 64:
                        CFG.set("download_threads", n)
                        cprint(f"âš™ï¸ ä¸‹è½½çº¿ç¨‹: {n}", "success")
                    else: cprint("èŒƒå›´: 1-64", "danger")

            elif cmd == "pages":
                if len(parts) > 1 and parts[1].isdigit():
                    n = int(parts[1])
                    if 1 <= n <= 10:
                        CFG.set("concurrency", n)
                        cprint(f"ğŸ“„ é¡µé¢å¹¶å‘: {n}", "success")
                    else: cprint("èŒƒå›´: 1-10", "danger")

            elif cmd == "thresh":
                if len(parts) > 1 and parts[1].isdigit():
                    n = int(parts[1])
                    CFG.set("stop_thresh", n)
                    cprint(f"ğŸ›‘ é˜ˆå€¼æ›´æ–°: {n} å¼ ", "success")
                else: cprint(f"å½“å‰é˜ˆå€¼: {CFG.get('stop_thresh')}", "info")
            
            elif cmd == "timeout":
                if len(parts) > 1 and parts[1].isdigit():
                    n = int(parts[1])
                    CFG.set("timeout", n)
                    cprint(f"â±ï¸ è¶…æ—¶è®¾ç½®: {n} ç§’", "success")
                else: cprint(f"å½“å‰è¶…æ—¶: {CFG.get('timeout')}ç§’", "info")

            elif cmd == "browser":
                if len(parts) > 1:
                    b_type = parts[1].lower()
                    if b_type in ["edge", "chrome"]:
                        CFG.set("browser_type", b_type.title())
                        cprint(f"ğŸŒ å†…æ ¸åˆ‡æ¢: {b_type.title()}", "success")
                    else: cprint("ä»…æ”¯æŒ edge/chrome", "danger")
                else: cprint(f"å½“å‰å†…æ ¸: {CFG.get('browser_type')}", "info")

            elif cmd == "img":
                if len(parts) > 1:
                    mode = parts[1].lower() == "on"
                    CFG.set("dl_images", mode)
                    cprint(f"ğŸ–¼ï¸ å›¾ç‰‡ä¸‹è½½: {'ON' if mode else 'OFF'}", "success")

            elif cmd == "vid":
                if len(parts) > 1:
                    mode = parts[1].lower() == "on"
                    CFG.set("dl_videos", mode)
                    cprint(f"ğŸ¬ è§†é¢‘ä¸‹è½½: {'ON' if mode else 'OFF'}", "success")

            elif cmd == "deep":
                if len(parts) > 1:
                    mode = parts[1].lower() == "on"
                    CFG.set("deep_scan", mode)
                    cprint(f"â›ï¸ ç©¿é€æ¨¡å¼: {'ON' if mode else 'OFF'}", "success")

            elif cmd == "head" or cmd == "headless":
                if len(parts) > 1:
                    mode = parts[1].lower() == "on"
                    CFG.set("headless", mode)
                    cprint(f"ğŸ‘» æ— å¤´æ¨¡å¼: {'ON' if mode else 'OFF'}", "success")

            elif cmd == "stats":
                print_stats()

            elif cmd == "export":
                engine.export_cookies()

            elif cmd == "config":
                cprint(json.dumps(CFG.data, indent=2, ensure_ascii=False), "secondary")

            elif cmd == "login":
                if engine.is_running: cprint("è¯·å…ˆ exit åœæ­¢å¼•æ“", "warning")
                else: asyncio.run(engine.run_login())
            
            else: cprint("æœªçŸ¥æŒ‡ä»¤ (è¾“å…¥ help æŸ¥çœ‹è¯´æ˜)", "secondary")

    except KeyboardInterrupt:
        engine.stop()
        cprint("\nå¼ºåˆ¶é€€å‡º...", "danger")

if __name__ == "__main__":
    main()